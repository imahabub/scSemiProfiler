{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425a9b4f-5d14-4735-9fc1-1cb31faeef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 22:16:23.466812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 22:16:23.466913: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 22:16:23.470433: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 22:16:23.754060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 22:16:25.270054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:pytorch_lightning.utilities.seed:Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/jingtao2/anaconda3/envs/deep/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/mnt/data/jingtao2/anaconda3/envs/deep/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import umap\n",
    "import anndata\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import faiss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "import scanpy as sc\n",
    "from numpy import linalg as LA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine as cos\n",
    "import anndata\n",
    "from matplotlib.pyplot import figure\n",
    "from multiprocessing import Process\n",
    "\n",
    "from fast_generator_ipsc import *\n",
    "from fast_functions_ipsc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1e7df-1598-4104-840f-cb34941f1672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f49082-693b-4f5a-9382-17c798de137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6013"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvmask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a217109d-2db3-47bc-8ed5-b5e461202469",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "pids=[]\n",
    "f = open('pids.txt','r')\n",
    "lines=f.readlines()\n",
    "for l in lines:\n",
    "    pids.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fda94c2-b52e-40b8-878b-9fbd83662dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprefile = 'init_representatives_'+str(BATCH_SIZE)+'.txt' \n",
    "clusterfile = 'init_cluster_labels_'+str(BATCH_SIZE)+'.txt' \n",
    "\n",
    "\n",
    "\n",
    "f= open(reprefile,'r')\n",
    "lines=f.readlines()\n",
    "init_representatives=[]\n",
    "for l in lines:\n",
    "    init_representatives.append(int(l.strip().split()[0]))\n",
    "f.close()\n",
    "\n",
    "f= open(clusterfile,'r')\n",
    "init_cluster_labels=[]\n",
    "lines=f.readlines()\n",
    "for l in lines:\n",
    "    init_cluster_labels.append(int(l.strip().split()[0]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb86d63-289d-408f-80f1-2a2f2a34cbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a134607-01c6-48fa-b458-8e8ebb1a883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 21]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cb3e46-2c22-4456-a18d-8e929747dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluation functions\n",
    "\n",
    "def faiss_knn(query, x, n_neighbors=1):\n",
    "    n_samples = x.shape[0]\n",
    "    n_features = x.shape[1]\n",
    "    x = np.ascontiguousarray(x)\n",
    "    \n",
    "    index = faiss.IndexFlatL2(n_features)\n",
    "    #index = faiss.IndexFlatIP(n_features)\n",
    "                  \n",
    "    index.add(x)\n",
    "    \n",
    "    if n_neighbors < 2:\n",
    "        neighbors = 2\n",
    "    else: \n",
    "        neighbors = n_neighbors\n",
    "    \n",
    "    weights, targets = index.search(query, neighbors)\n",
    "\n",
    "    #sources = np.repeat(np.arange(n_samples), neighbors)\n",
    "    #targets = targets.flatten()\n",
    "    #weights = weights.flatten()\n",
    "    weights = weights[:,:n_neighbors]\n",
    "    if -1 in targets:\n",
    "        raise InternalError(\"Not enough neighbors were found. Please consider \"\n",
    "                            \"reducing the number of neighbors.\")\n",
    "    return weights\n",
    "\n",
    "def pearson_compare(query,x):\n",
    "    return 0\n",
    "\n",
    "def cos_compare(query,x):\n",
    "    return 0\n",
    "\n",
    "\n",
    "def pca_compare(query,x):\n",
    "    qx = np.concatenate([query,x],axis=0)\n",
    "    qxpca = PCA(n_components=100)\n",
    "    dx=qxpca.fit_transform(qx)\n",
    "    \n",
    "    newq = dx[:query.shape[0],:].copy(order='C')\n",
    "    newx = dx[query.shape[0]:,:].copy(order='C')\n",
    "    score = faiss_knn(newq,newx,n_neighbors=1)\n",
    "    return score\n",
    "\n",
    "def umap_compare(query,x):\n",
    "    qx = np.concatenate([query,x],axis=0)\n",
    "    qxpca = PCA(n_components=100)\n",
    "    dpca=qxpca.fit_transform(qx)\n",
    "    umap_reduc=umap.UMAP(min_dist=0.5,spread=1.0,negative_sample_rate=5 )\n",
    "    dx = umap_reduc.fit_transform(dpca)\n",
    "    newq = dx[:query.shape[0],:].copy(order='C')\n",
    "    newx = dx[query.shape[0]:,:].copy(order='C')\n",
    "    score = faiss_knn(newq,newx,n_neighbors=1)\n",
    "    return score\n",
    "\n",
    "def knncompare(query,x,n_neighbors=1,dist='PCA'):\n",
    "    if dist == 'Euclidean':\n",
    "        score = faiss_knn(query,x,n_neighbors=n_neighbors)\n",
    "        score2 = faiss_knn(x,query,n_neighbors=n_neighbors)\n",
    "    elif dist == 'Pearson':\n",
    "        score = pearson_compare(query,x)\n",
    "        score2 = pearson_compare(x,query)\n",
    "    elif dist == 'cos':\n",
    "        score = cos_compare(query,x)\n",
    "        score2 = cos_compare(x,query)\n",
    "    elif dist == 'PCA':\n",
    "        score = pca_compare(query,x)\n",
    "        score2 = pca_compare(x,query)\n",
    "    elif dist == 'UMAP':\n",
    "        score = umap_compare(query,x)\n",
    "        score2 = umap_compare(x,query)\n",
    "    else:\n",
    "        score = 0\n",
    "        print('distance option not found')\n",
    "        \n",
    "    return (score.mean() + score2.mean())/2\n",
    "\n",
    "def normtotal(x,h=1e4):\n",
    "    ratios = h/x.sum(axis=1)\n",
    "    x=(x.T*ratios).T\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56946e79-432f-4efd-a9c9-3fc4bef112b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002c8fb8-9997-4903-84f6-7c02218bd944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339.18777\n"
     ]
    }
   ],
   "source": [
    "bulkdata = anndata.read_h5ad('bulkdata.h5ad')\n",
    "print(bulkdata.X.max())\n",
    "sc.pp.log1p(bulkdata)\n",
    "sc.tl.pca(bulkdata, svd_solver='arpack',n_comps=20)\n",
    "reduced_bulk = bulkdata.obsm['X_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27c4225-f186-498e-b207-8c51c9faf476",
   "metadata": {},
   "outputs": [],
   "source": [
    "sids=pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978aac30-f63e-4ed9-bf28-58704e6d1cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 4245.0713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load ground truth\n",
    "\n",
    "hvmask = np.load('hvmask.npy')\n",
    "setmask = np.load('hvset.npy')\n",
    "totalsids = []\n",
    "gts=[]\n",
    "for i in range(len(sids)):\n",
    "    sid = sids[i]\n",
    "    adata = anndata.read_h5ad('sample_sc/' + sid + '.h5ad')\n",
    "    gt = np.array(adata[:,hvmask].X.todense())\n",
    "    gts.append(gt)\n",
    "    for j in range(len(gt)):\n",
    "        totalsids.append(i)\n",
    "    print(i,end=', ')\n",
    "\n",
    "print(adata.X.max())\n",
    "del adata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c067a9b6-4b25-42d9-bd20-4151d3bfaaeb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 11,\n",
       " 23,\n",
       " 15,\n",
       " 22,\n",
       " 1,\n",
       " 14,\n",
       " 24,\n",
       " 17,\n",
       " 9,\n",
       " 6,\n",
       " 18,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 19,\n",
       " 10,\n",
       " 7,\n",
       " 20,\n",
       " 3,\n",
       " 0,\n",
       " 16,\n",
       " 13]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[12,\n",
    " 11,\n",
    " 23,\n",
    " 15,\n",
    " 22,\n",
    " 1,\n",
    " 14,\n",
    " 24,\n",
    " 17,\n",
    " 9,\n",
    " 6,\n",
    " 18,\n",
    " 4,\n",
    " 2,\n",
    " 5,\n",
    " 19,\n",
    " 10,\n",
    " 7,\n",
    " 20,\n",
    " 3,\n",
    " 0,\n",
    " 16,\n",
    " 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f47021b-f35f-47e6-bb55-96efca045bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomlist = list(range(len(pids)))\n",
    "for r in init_representatives:\n",
    "    randomlist.remove(r)\n",
    "np.random.shuffle(randomlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0bd560-9319-4638-8111-9679eefd149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdimsemis = []\n",
    "xdimgts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c294b5-023a-4fc4-9f0d-e6f332ef9c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## active learning functions \n",
    "def pick_batch(reduced_bulk=reduced_bulk,\\\n",
    "                representatives=init_representatives,\\\n",
    "                cluster_labels=init_cluster_labels,\\\n",
    "                xdimsemis=xdimsemis,\\\n",
    "                xdimgts=xdimgts,\\\n",
    "                discount_rate = 1,\\\n",
    "                semi_dis_rate = 1,\\\n",
    "                batch_size=BATCH_SIZE\\\n",
    "               ):\n",
    "    # \n",
    "    lhet = []\n",
    "    lmp = [] \n",
    "    for i in range(len(representatives)):\n",
    "        cluster_heterogeneity,in_cluster_uncertainty,uncertain_patient=compute_cluster_heterogeneity(cluster_number=i,\\\n",
    "                            reduced_bulk=reduced_bulk,\\\n",
    "                           representatives=init_representatives,\\\n",
    "                            cluster_labels=init_cluster_labels,\\\n",
    "                            xdimsemis=xdimsemis,\\\n",
    "                            xdimgts=xdimgts,\\\n",
    "                            discount_rate = 1,\\\n",
    "                            semi_dis_rate = 1\\\n",
    "                           )\n",
    "        lhet.append(cluster_heterogeneity)\n",
    "        lmp.append(uncertain_patient)\n",
    "    \n",
    "    \n",
    "    new_representatives = copy.deepcopy(representatives)\n",
    "    for i in range(batch_size):\n",
    "        mp_index = np.array(lhet).argmax()\n",
    "        mp = lmp[mp_index]\n",
    "        \n",
    "        new_representatives.append(mp)\n",
    "        lhet.pop(mp_index)\n",
    "        lmp.pop(mp_index)\n",
    "    \n",
    "    new_cluster_labels= update_membership(reduced_bulk=reduced_bulk,\\\n",
    "                      representatives=new_representatives)\n",
    "    \n",
    "    return new_representatives,new_cluster_labels\n",
    "np.random.seed(0)\n",
    "def passive_pick_batch(reduced_bulk=reduced_bulk,\\\n",
    "                representatives=init_representatives,\\\n",
    "                cluster_labels=init_cluster_labels,\\\n",
    "                xdimsemis=xdimsemis,\\\n",
    "                xdimgts=xdimgts,\\\n",
    "                discount_rate = 1,\\\n",
    "                semi_dis_rate = 1,\\\n",
    "                batch_size=BATCH_SIZE\\\n",
    "               ):\n",
    "    '''\n",
    "    new_representatives = representatives\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        newrep = np.random.randint(0,len(pids))\n",
    "            \n",
    "        while int(newrep) in representatives:\n",
    "            newrep = np.random.randint(0,len(pids))\n",
    "        new_representatives.append(int(newrep))'''\n",
    "    \n",
    "    offset = len(representatives)\n",
    "    new_representatives = representatives + randomlist[offset:offset+2]\n",
    "    new_cluster_labels= update_membership(reduced_bulk=reduced_bulk,\\\n",
    "                      representatives=new_representatives)\n",
    "    \n",
    "    \n",
    "    return new_representatives,new_cluster_labels\n",
    "\n",
    "def pick_batch_eee(reduced_bulk=reduced_bulk,\\\n",
    "                representatives=init_representatives,\\\n",
    "                cluster_labels=init_cluster_labels,\\\n",
    "                xdimsemis=xdimsemis,\\\n",
    "                xdimgts=xdimgts,\\\n",
    "                discount_rate = 1,\\\n",
    "                semi_dis_rate = 1,\\\n",
    "                batch_size=BATCH_SIZE\\\n",
    "               ):\n",
    "    # \n",
    "    lhet = []\n",
    "    lmp = [] \n",
    "    for i in range(len(representatives)):\n",
    "        cluster_heterogeneity,in_cluster_uncertainty,uncertain_patient=compute_cluster_heterogeneity(cluster_number=i,\\\n",
    "                            reduced_bulk=reduced_bulk,\\\n",
    "                           representatives=representatives,\\\n",
    "                            cluster_labels=cluster_labels,\\\n",
    "                            xdimsemis=xdimsemis,\\\n",
    "                            xdimgts=xdimgts,\\\n",
    "                            discount_rate = 1,\\\n",
    "                            semi_dis_rate = 1\\\n",
    "                           )\n",
    "        lhet.append(cluster_heterogeneity)\n",
    "        lmp.append(uncertain_patient)\n",
    "    \n",
    "    new_representatives = copy.deepcopy(representatives)\n",
    "    new_cluster_labels = copy.deepcopy(cluster_labels)\n",
    "    print('heterogeneities: ',lhet)\n",
    "    for i in range(batch_size):\n",
    "        new_num = len(new_representatives)\n",
    "        mp_index = np.array(lhet).argmax()\n",
    "        print(mp_index)\n",
    "        lhet[mp_index] = -999\n",
    "        bestp, new_cluster_labels, hets = best_patient(cluster_labels=new_cluster_labels,representatives=new_representatives,\\\n",
    "                 reduced_bulk=reduced_bulk,cluster_num=mp_index,new_num=new_num)\n",
    "        \n",
    "        new_representatives = new_representatives + [bestp]\n",
    "    \n",
    "    return new_representatives,new_cluster_labels\n",
    "\n",
    "def best_patient(cluster_labels=init_cluster_labels,representatives=init_representatives,\\\n",
    "                 reduced_bulk=reduced_bulk,cluster_num=0,new_num=None):\n",
    "    if new_num == None:\n",
    "        new_num = len(representatives)\n",
    "    pindices = np.where(np.array(cluster_labels)==cluster_num)[0]\n",
    "    representative = representatives[cluster_num]\n",
    "    hets=[]\n",
    "    potential_new_labels = []\n",
    "    for i in range(len(pindices)):\n",
    "        potential_new_label = copy.deepcopy(cluster_labels)\n",
    "        newrepre = pindices[i]\n",
    "        het = 0\n",
    "        if newrepre in representatives:\n",
    "            hets.append(9999)\n",
    "            potential_new_labels.append(potential_new_label)\n",
    "            continue\n",
    "        for j in range(len(pindices)):\n",
    "            brepre = reduced_bulk[representative]\n",
    "            brepre2 = reduced_bulk[newrepre]\n",
    "            bj = reduced_bulk[pindices[j]]\n",
    "            bdist1 = (brepre - bj)**2\n",
    "            bdist1 = bdist1.sum()\n",
    "            bdist1 = bdist1**0.5\n",
    "            bdist2 = (brepre2 - bj)**2\n",
    "            bdist2 = bdist2.sum()\n",
    "            bdist2 = bdist2**0.5\n",
    "            \n",
    "            if bdist1 > bdist2:\n",
    "                #print(pindices[j])\n",
    "                het = het + bdist2\n",
    "                potential_new_label[pindices[j]]=new_num\n",
    "            else:\n",
    "                het = het + bdist1\n",
    "        hets.append(het)\n",
    "        potential_new_labels.append(potential_new_label)\n",
    "    hets = np.array(hets)\n",
    "    bestp = pindices[np.argmin(hets)]\n",
    "    new_cluster_labels = potential_new_labels[np.argmin(hets)]\n",
    "    return bestp, new_cluster_labels, hets\n",
    "\n",
    "def update_membership(reduced_bulk=reduced_bulk,\\\n",
    "                      representatives=init_representatives,\\\n",
    "                      \n",
    "                     ):\n",
    "    new_cluster_labels = []\n",
    "    for i in range(len(reduced_bulk)):\n",
    "        \n",
    "        dists=[]\n",
    "        #dist to repres\n",
    "        for j in representatives:\n",
    "            bdist = (reduced_bulk[j] - reduced_bulk[i])**2 \n",
    "            bdist = bdist.sum()\n",
    "            bdist = bdist**0.5\n",
    "            dists.append(bdist)\n",
    "        membership = np.array(dists).argmin()\n",
    "        new_cluster_labels.append(membership)\n",
    "    return new_cluster_labels\n",
    "\n",
    "def compute_cluster_heterogeneity(cluster_number=0,\\\n",
    "                            reduced_bulk=reduced_bulk,\\\n",
    "                           representatives=init_representatives,\\\n",
    "                            cluster_labels=init_cluster_labels,\\\n",
    "                            xdimsemis=xdimsemis,\\\n",
    "                            xdimgts=xdimgts,\\\n",
    "                            discount_rate = 1,\\\n",
    "                            semi_dis_rate = 1\\\n",
    "                           ):\n",
    "    semiflag=0\n",
    "    \n",
    "    representative = representatives[cluster_number]\n",
    "    in_cluster_uncertainty = []\n",
    "    cluster_labels = np.array(cluster_labels)\n",
    "    cluster_patient_indices = np.where(cluster_labels==cluster_number)[0]\n",
    "    \n",
    "    for i in range(len(cluster_patient_indices)): # number of patients in this cluster except the representative\n",
    "        \n",
    "        patient_index = cluster_patient_indices[i]\n",
    "        \n",
    "        if patient_index in representatives:\n",
    "            in_cluster_uncertainty.append(0)\n",
    "            continue\n",
    "            \n",
    "        # distance between this patient and representative\n",
    "        bdist = (reduced_bulk[representative] - reduced_bulk[patient_index])**2 \n",
    "        bdist = bdist.sum()\n",
    "        bdist = bdist**0.5\n",
    "        \n",
    "        ma = np.array(xdimsemis[patient_index]).copy(order='C')\n",
    "        mb = np.array(xdimgts[representative]).copy(order='C')\n",
    "        sdist = (faiss_knn(ma,mb,n_neighbors=1).mean())\n",
    "        \n",
    "        semiloss = np.log(1+gts[patient_index].sum(axis=0))- np.log(1+semis[patient_index].sum(axis=0))\n",
    "        semiloss = semiloss**2\n",
    "        semiloss = semiloss.sum()\n",
    "        semiloss = semiloss**0.5\n",
    "        \n",
    "        #print(bdist,sdist,semiloss)\n",
    "        \n",
    "        uncertainty = bdist + sdist*discount_rate + semi_dis_rate * semiloss\n",
    "        \n",
    "        in_cluster_uncertainty.append(uncertainty)\n",
    "        \n",
    "    cluster_heterogeneity = np.array(in_cluster_uncertainty).sum()\n",
    "    \n",
    "    uncertain_patient = cluster_patient_indices[np.array(in_cluster_uncertainty).argmax()] \n",
    "\n",
    "    return cluster_heterogeneity,in_cluster_uncertainty,uncertain_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e73fc87-4626-4ca3-97d5-4a122b22b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9fd66-5ffd-42e5-b332-64ed5a1a4784",
   "metadata": {},
   "source": [
    "### start semiprofiling loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53de708c-90ae-473b-91f5-71571887d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi processes\n",
    "\n",
    "def multisemi(l,device,rnd):\n",
    "    if l ==[]:\n",
    "        return\n",
    "    for i in l:\n",
    "        print('start semiprofiling patient',str(i),'using',device)\n",
    "        os.system('/mnt/data/jingtao2/anaconda3/envs/deep/bin/python semicommand.py '+str(i)+' '+str(device) + ' '+str(rnd)) \n",
    "    return \n",
    "\n",
    "def multirecon(i,device):\n",
    "    print('start recon patient',str(i),'using',device)\n",
    "    pid=pids[i]\n",
    "    fastrecon(pid=pid,tgtpid=None,device=device,k=15,diagw=1,vaesteps=100,gansteps=100,save=True,path=None)\n",
    "    return\n",
    "\n",
    "def multirecon2(i,reconmodel,device):\n",
    "    print('start recon2 patient',str(i),'using',device)\n",
    "    pid=pids[i]\n",
    "    reconst_pretrain2(pid,reconmodel,device,k=15,diagw=1.0,vaesteps=400,gansteps=50,save=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a612933-8d1d-4afb-845b-a4682bc1c228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = [0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,6,6,7,7,8,8,9,9]\n",
    "len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1a1902-0a88-4415-9af4-d92e8bdb3c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54aa3742-9554-42dd-918f-d33de9e7fc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start initial round\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "2.5410601717885584 for loading semi\n",
      "\n",
      "18.61342932912521 for pca\n",
      "naive: 146.49184\n",
      "semi: 122.28375\n",
      "upperbound: 162.37105\n",
      "lowerbound; 58.915443\n",
      "normed naive: 0.84651184\n",
      "normed semi: 0.61251694\n",
      "0.3820583939086646  for evaluation\n",
      "start round 2\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "1.504887707065791 for loading semi\n",
      "\n",
      "14.405957086011767 for pca\n",
      "naive: 138.93855\n",
      "semi: 117.8523\n",
      "upperbound: 162.74463\n",
      "lowerbound; 62.94796\n",
      "normed naive: 0.7614542\n",
      "normed semi: 0.5501621\n",
      "0.3916596048511565  for evaluation\n",
      "start round 3\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "1.5979313310235739 for loading semi\n",
      "\n",
      "15.259540284052491 for pca\n",
      "naive: 128.50606\n",
      "semi: 110.12764\n",
      "upperbound: 162.98651\n",
      "lowerbound; 61.268536\n",
      "normed naive: 0.6610191\n",
      "normed semi: 0.48033896\n",
      "0.32758450089022517  for evaluation\n",
      "start round 4\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "1.3295429300051183 for loading semi\n",
      "\n",
      "15.880831731949002 for pca\n",
      "naive: 122.357254\n",
      "semi: 106.93032\n",
      "upperbound: 163.0764\n",
      "lowerbound; 64.080925\n",
      "normed naive: 0.5886767\n",
      "normed semi: 0.43284196\n",
      "0.26481752819381654  for evaluation\n",
      "start round 5\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "1.126715332036838 for loading semi\n",
      "\n",
      "21.66475254902616 for pca\n",
      "naive: 114.18299\n",
      "semi: 99.91368\n",
      "upperbound: 163.10426\n",
      "lowerbound; 62.424282\n",
      "normed naive: 0.5140914\n",
      "normed semi: 0.37236202\n",
      "0.26907305396161973  for evaluation\n",
      "start round 6\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "0.9027385420631617 for loading semi\n",
      "\n",
      "17.486160350963473 for pca\n",
      "naive: 108.16571\n",
      "semi: 96.597725\n",
      "upperbound: 163.14493\n",
      "lowerbound; 63.91343\n",
      "normed naive: 0.44594994\n",
      "normed semi: 0.3293742\n",
      "0.21738580614328384  for evaluation\n",
      "start round 7\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "0.7893077968619764 for loading semi\n",
      "\n",
      "27.168872740119696 for pca\n",
      "naive: 99.68338\n",
      "semi: 89.35365\n",
      "upperbound: 163.16771\n",
      "lowerbound; 63.796658\n",
      "normed naive: 0.3611386\n",
      "normed semi: 0.25718755\n",
      "0.1707568580750376  for evaluation\n",
      "start round 8\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "reconiMGL_D1_rep3_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep1_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D1_rep3_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep1_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "3.293184933019802 for loading semi\n",
      "\n",
      "110.82244449318387 for pca\n",
      "naive: 92.342674\n",
      "semi: 83.82923\n",
      "upperbound: 163.17088\n",
      "lowerbound; 62.08739\n",
      "normed naive: 0.29930982\n",
      "normed semi: 0.21508794\n",
      "0.12798262597061694  for evaluation\n",
      "start round 9\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "reconiMGL_D1_rep3_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep2_TPMexist\n",
      "reconiMGL_D2_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D1_rep3_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep2_TPMexist\n",
      "recon2iMGL_D2_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "4.381663233041763 for loading semi\n",
      "\n",
      "139.72470506397076 for pca\n",
      "naive: 84.48306\n",
      "semi: 77.69353\n",
      "upperbound: 163.17654\n",
      "lowerbound; 61.464237\n",
      "normed naive: 0.22631307\n",
      "normed semi: 0.15956073\n",
      "0.12482443591579795  for evaluation\n",
      "start round 10\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "reconiMGL_D1_rep3_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep2_TPMexist\n",
      "reconiMGL_D2_rep2_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep1_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D1_rep3_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep2_TPMexist\n",
      "recon2iMGL_D2_rep2_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep1_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "0.3992083359044045 for loading semi\n",
      "\n",
      "16.46625293721445 for pca\n",
      "naive: 77.888084\n",
      "semi: 73.17869\n",
      "upperbound: 163.18182\n",
      "lowerbound; 61.044914\n",
      "normed naive: 0.16490777\n",
      "normed semi: 0.118799105\n",
      "0.07364629511721432  for evaluation\n",
      "start round 11\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "reconiMGL_D1_rep3_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep2_TPMexist\n",
      "reconiMGL_D2_rep2_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep1_TPMexist\n",
      "reconiMGL_D0_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D1_rep3_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep2_TPMexist\n",
      "recon2iMGL_D2_rep2_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep1_TPMexist\n",
      "recon2iMGL_D0_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "0.4591256680432707 for loading semi\n",
      "\n",
      "119.11264495900832 for pca\n",
      "naive: 70.02808\n",
      "semi: 66.80184\n",
      "upperbound: 163.16527\n",
      "lowerbound; 59.153656\n",
      "normed naive: 0.10455013\n",
      "normed semi: 0.07353204\n",
      "0.050613432889804244  for evaluation\n",
      "start round 12\n",
      "reconiMGL_D2_rep3_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep1_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep1_TPMexist\n",
      "reconiMGL_T0901317_30nM_rep2_TPMexist\n",
      "reconiMGL_D0_rep2_TPMexist\n",
      "reconiMGL_D4_rep3_TPMexist\n",
      "reconiMGL_T0901317_100nM_rep2_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep1_TPMexist\n",
      "reconiMGL_D2_rep1_TPMexist\n",
      "reconiMGL_GW3965_30nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep2_TPMexist\n",
      "reconiMGL_D0_rep3_TPMexist\n",
      "reconiMGL_D1_rep3_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep1_TPMexist\n",
      "reconiMGL_D3_rep2_TPMexist\n",
      "reconiMGL_D2_rep2_TPMexist\n",
      "reconiMGL_GW3965_300nM_rep2_TPMexist\n",
      "reconiMGL_D1_rep1_TPMexist\n",
      "reconiMGL_D0_rep1_TPMexist\n",
      "reconiMGL_DMSO_rep2_TPMexist\n",
      "reconiMGL_D4_rep2_TPMexist\n",
      "recon2iMGL_D2_rep3_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep1_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep1_TPMexist\n",
      "recon2iMGL_T0901317_30nM_rep2_TPMexist\n",
      "recon2iMGL_D0_rep2_TPMexist\n",
      "recon2iMGL_D4_rep3_TPMexist\n",
      "recon2iMGL_T0901317_100nM_rep2_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep1_TPMexist\n",
      "recon2iMGL_D2_rep1_TPMexist\n",
      "recon2iMGL_GW3965_30nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep2_TPMexist\n",
      "recon2iMGL_D0_rep3_TPMexist\n",
      "recon2iMGL_D1_rep3_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep1_TPMexist\n",
      "recon2iMGL_D3_rep2_TPMexist\n",
      "recon2iMGL_D2_rep2_TPMexist\n",
      "recon2iMGL_GW3965_300nM_rep2_TPMexist\n",
      "recon2iMGL_D1_rep1_TPMexist\n",
      "recon2iMGL_D0_rep1_TPMexist\n",
      "recon2iMGL_DMSO_rep2_TPMexist\n",
      "recon2iMGL_D4_rep2_TPMexist\n",
      "exist\n",
      "exist\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
      "0.37527951784431934 for loading semi\n",
      "\n",
      "22.31347471103072 for pca\n",
      "naive: 66.03311\n",
      "semi: 63.89076\n",
      "upperbound: 163.12242\n",
      "lowerbound; 59.54421\n",
      "normed naive: 0.06264737\n",
      "normed semi: 0.04196394\n",
      "0.04776957700960338  for evaluation\n"
     ]
    }
   ],
   "source": [
    "### pipeline\n",
    "\n",
    "\n",
    "### passive learning\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for seqp in range(2,len(pids),BATCH_SIZE):\n",
    "        ### load this rounds representatives and cluster labels\n",
    "        if seqp <= BATCH_SIZE:\n",
    "            rnd=int(seqp/BATCH_SIZE)\n",
    "            print('start initial round')\n",
    "            reprefile = 'training_rec/init_representatives_'+str(BATCH_SIZE)+'.txt' \n",
    "            clusterfile = 'training_rec/init_cluster_labels_'+str(BATCH_SIZE)+'.txt' \n",
    "\n",
    "            f = open(reprefile,'r')\n",
    "            lines=f.readlines()\n",
    "            representatives=[]\n",
    "            for l in lines:\n",
    "                representatives.append(int(l.strip().split()[0]))\n",
    "            f.close()\n",
    "\n",
    "            f= open(clusterfile,'r')\n",
    "            cluster_labels=[]\n",
    "            lines=f.readlines()\n",
    "            for l in lines:\n",
    "                cluster_labels.append(int(l.strip().split()[0]))\n",
    "            f.close()\n",
    "            \n",
    "        else:\n",
    "            rnd = int(seqp/BATCH_SIZE)\n",
    "            print('start round '+str(rnd))\n",
    "            reprefile = 'training_rec/eer_representatives_'+str(rnd)+'.txt' \n",
    "            clusterfile = 'training_rec/eer_cluster_labels_'+str(rnd)+'.txt' \n",
    "\n",
    "            f= open(reprefile,'r')\n",
    "            lines=f.readlines()\n",
    "            representatives=[]\n",
    "            for l in lines:\n",
    "                representatives.append(int(l.strip().split()[0]))\n",
    "            f.close()\n",
    "\n",
    "            f= open(clusterfile,'r')\n",
    "            cluster_labels=[]\n",
    "            lines=f.readlines()\n",
    "            for l in lines:\n",
    "                cluster_labels.append(int(l.strip().split()[0]))\n",
    "            f.close()\n",
    "        ### end of loading representatives and cluster labels\n",
    "\n",
    "\n",
    "\n",
    "        ### reconstruction stage 1\n",
    "        c=0\n",
    "        #procs=[]\n",
    "        for rp in representatives:#new_representatives:\n",
    "            pid = pids[rp]\n",
    "            if ('fast_reconst1_'+pid) in os.listdir('ipsc_models'):\n",
    "                print('recon' + str(pid) + 'exist')\n",
    "                continue\n",
    "            device = 'cuda:' + str(c%8)\n",
    "            fastrecon(pid=pid,tgtpid=None,device=device,k=15,diagw=1,vaesteps=100,gansteps=100,save=True,path=None)\n",
    "            \n",
    "            #proc = Process(target=multirecon, args=(rp,device))\n",
    "            #procs.append(proc)\n",
    "            #proc.start()\n",
    "            c=c+1\n",
    "        \n",
    "\n",
    "        #for proc in procs:\n",
    "        #        proc.join()\n",
    "        ### end of recon stage 1\n",
    "\n",
    "        ### reconstruction stage 2\n",
    "        i=0\n",
    "        c=0\n",
    "        procs=[]\n",
    "        for rp in representatives:##new_representatives:\n",
    "            pid = pids[rp]\n",
    "            device = 'cuda:' + str(c%8)\n",
    "            if ('fastreconst2_'+pid) in os.listdir('ipsc_models'):\n",
    "                print('recon2' + str(pid) + 'exist')\n",
    "                continue\n",
    "            adata,adj,variances,bulk,geneset_len = setdata(pid,None,device=device,k=15,diagw=1.0)\n",
    "            reconmodel = fastgenerator(adj = adj,variances = variances,markermask = None,bulk=bulk,geneset_len = geneset_len,adata=adata,\\\n",
    "                        n_hidden=256,n_latent=32,dropout_rate=0,countbulkweight=0,logbulkweight=0,absbulkweight=0,abslogbulkweight=0,\\\n",
    "                        power=2,corrbulkweight=0,meanbias=0)\n",
    "            reconmodel.module.load_state_dict(torch.load('ipsc_models/fast_reconst1_'+str(pid)))\n",
    "            reconst_pretrain2(pid,reconmodel,device,k=15,diagw=1.0,vaesteps=50,gansteps=50,save=True)\n",
    "            \n",
    "            \n",
    "            #proc = Process(target=multirecon2, args=(rp,reconmodel,device))\n",
    "            #procs.append(proc)\n",
    "            #proc.start()\n",
    "            #c=c+1\n",
    "            #i+=1\n",
    "        #for proc in procs:\n",
    "        #        proc.join()\n",
    "        ### end of recon stage 2\n",
    "\n",
    "\n",
    "        \n",
    "        ### semi profiling\n",
    "        procs = []\n",
    "        c=0\n",
    "\n",
    "        l0 = []\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        l3 = []\n",
    "        l4 = []\n",
    "        l5 = []\n",
    "        l6 = []\n",
    "        l7 = []\n",
    "\n",
    "        for i in range(0,6):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l0.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(6,12):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l1.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(12,18):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l2.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(18,25):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l3.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "                \n",
    "        '''\n",
    "        for i in range(9,12):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l4.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(6,9):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l5.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(3,6):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l6.append(i)\n",
    "            else:\n",
    "                print('exist')\n",
    "        for i in range(0,3):\n",
    "            if i in representatives:\n",
    "                continue\n",
    "            reprepid = pids[representatives[cluster_labels[i]]]\n",
    "            if ('fast'+ reprepid+'_to_'+str(pids[i])+'.npy') not in os.listdir('semidata'):\n",
    "                l7.append(i)\n",
    "            else:\n",
    "                print('exist')'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        proc = Process(target=multisemi, args=(l0,'cuda:2',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l1,'cuda:3',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l2,'cuda:0',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l3,'cuda:1',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        \n",
    "        \n",
    "        proc = Process(target=multisemi, args=(l4,'cuda:4',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l5,'cuda:5',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l6,'cuda:6',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        proc = Process(target=multisemi, args=(l7,'cuda:7',rnd))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        for proc in procs:\n",
    "            proc.join()\n",
    "        ### end semi \n",
    "\n",
    "        tids = copy.deepcopy(totalsids)\n",
    "        ### load new semi results\n",
    "        t_start = timeit.default_timer()\n",
    "        semis=[]\n",
    "        for i in range(len(pids)):\n",
    "            pid = pids[i]\n",
    "            repre = representatives[cluster_labels[i]]\n",
    "            reprepid = pids[repre]\n",
    "            if reprepid==pid:\n",
    "                xsem = gts[i]\n",
    "                semis.append(xsem)\n",
    "            else:\n",
    "                xsem = np.load('semidata/fast'+ reprepid+'_to_'+pid+'.npy')\n",
    "                xsem = xsem*(xsem>10)                                   ############### thresholding\n",
    "                semis.append(xsem)\n",
    "            \n",
    "            for j in range(len(xsem)):\n",
    "                tids.append(i)\n",
    "            print(i,end=', ')\n",
    "\n",
    "        tgroup = []\n",
    "        for i in tids:\n",
    "            tgroup.append(group[i])\n",
    "        tgroup = np.array(tgroup)\n",
    "        \n",
    "        t_end = timeit.default_timer()\n",
    "        print()\n",
    "        print(str(t_end-t_start),'for loading semi')\n",
    "        ### end of loading semi\n",
    "\n",
    "\n",
    "\n",
    "        ### PCA\n",
    "        t_start = timeit.default_timer()\n",
    "        \n",
    "        X = np.concatenate([np.concatenate(gts,axis=0),np.concatenate(semis,axis=0)],axis=0)\n",
    "        X = np.log(X+1)\n",
    "        reducer =  PCA(n_components = 100)#,svd_solver = 'randomized')#randomized_svd(n_components=100)  #PCA(n_components=100)#\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "        t_end = timeit.default_timer()\n",
    "        print()\n",
    "        print(str(t_end-t_start),'for pca')\n",
    "        ### end of pca\n",
    "\n",
    "\n",
    "        ### reduced data for patients\n",
    "        xdimgts=[]\n",
    "        xdimsemis=[]\n",
    "        offset=0\n",
    "        xused = X_reduced#X_UMAP # X_PCA\n",
    "\n",
    "        for i in range(len(pids)):\n",
    "            xdimgts.append(xused[offset:(offset+gts[i].shape[0]),:])\n",
    "            offset = offset+gts[i].shape[0]\n",
    "        lengt = offset\n",
    "        for i in range(len(pids)):\n",
    "            xdimsemis.append(xused[offset:(offset+semis[i].shape[0]),:])\n",
    "            offset = offset+semis[i].shape[0]\n",
    "        ### end \n",
    "\n",
    "        \n",
    "        ### lowerbound\n",
    "        \n",
    "        lbgt = copy.deepcopy(X_reduced)#[:lengt])\n",
    "        np.random.shuffle(lbgt)\n",
    "        lbgt1 = lbgt[:lbgt.shape[0]//2,:]\n",
    "        lbgt2 = lbgt[lbgt.shape[0]//2:,:]\n",
    "        ma = np.array(lbgt1).copy(order='C')\n",
    "        mb = np.array(lbgt2).copy(order='C')\n",
    "        lowerbound = list(faiss_knn(ma,mb,n_neighbors=1)) + list(faiss_knn(mb,ma,n_neighbors=1))\n",
    "        lowerbound = np.array(lowerbound).mean()\n",
    "        \n",
    "        '''\n",
    "        for i in range(len(np.unique(group))):\n",
    "            lbgt = copy.deepcopy(X_reduced[tgroup == i])\n",
    "            np.random.shuffle(lbgt)\n",
    "            lbgt1 = lbgt[:lbgt.shape[0]//2,:]\n",
    "            lbgt2 = lbgt[lbgt.shape[0]//2:,:]\n",
    "            ma0 = np.array(lbgt1).copy(order='C')\n",
    "            mb0 = np.array(lbgt2).copy(order='C')\n",
    "            lowerbound0 = list(faiss_knn(ma0,mb0,n_neighbors=1)) + list(faiss_knn(ma0,mb0,n_neighbors=1))\n",
    "            lowerbound = lowerbound + lowerbound0\n",
    "        lowerbound = lowerbound / len(np.unique(group))'''\n",
    "        \n",
    "        ### upperbound\n",
    "        \n",
    "        ubscores = []\n",
    "        for i in range(len(pids)):\n",
    "            gt = xdimgts[i]\n",
    "            for j in range(i+1,len(pids)):\n",
    "                randomidx = j\n",
    "            #randomidx = np.random.randint(0,len(pids))\n",
    "                gtr = xdimgts[randomidx]\n",
    "                ma = np.array(gt).copy(order='C')\n",
    "                mb = np.array(gtr).copy(order='C')\n",
    "                ubscore = list(faiss_knn(ma,mb,n_neighbors=1)) + list(faiss_knn(mb,ma,n_neighbors=1))\n",
    "                ubscore = np.array(ubscore)\n",
    "                ubscores.append(np.array(ubscore).mean())\n",
    "        upperbound = np.array(ubscores).mean()\n",
    "        \n",
    "        '''\n",
    "        ubscores = []\n",
    "        for i in range(200):\n",
    "            i=i%len(pids)\n",
    "            gt = xdimgts[i]\n",
    "            randomidx = np.random.randint(0,len(pids))\n",
    "            gtgroup = group[i]\n",
    "            rdgroup = group[randomidx]\n",
    "            while rdgroup == gtgroup:\n",
    "                randomidx = np.random.randint(0,len(pids))\n",
    "                rdgroup = group[randomidx]\n",
    "            gtr = xdimgts[randomidx]\n",
    "            ma = np.array(gt).copy(order='C')\n",
    "            mb = np.array(gtr).copy(order='C')\n",
    "            ubscore = list(faiss_knn(ma,mb,n_neighbors=1)) + list(faiss_knn(mb,ma,n_neighbors=1))\n",
    "            ubscores.append(np.array(ubscore).mean())\n",
    "        upperbound = np.array(ubscores).mean()'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### semi evaluation\n",
    "        t_start = timeit.default_timer()\n",
    "        scores = []\n",
    "        for i in range(len(pids)):\n",
    "            pid = pids[i]\n",
    "            if i in representatives:\n",
    "                scores.append(lowerbound)\n",
    "                continue\n",
    "            gt = xdimgts[i]\n",
    "            xs = xdimsemis[i]\n",
    "            ma = np.array(gt).copy(order='C')\n",
    "            mb = np.array(xs).copy(order='C')\n",
    "            err1 = faiss_knn(ma,mb,n_neighbors=1)\n",
    "            err2 = faiss_knn(mb,ma,n_neighbors=1)\n",
    "            err = list(err1) + list(err2)\n",
    "            err = (np.array(err)).mean()\n",
    "            scores.append(err)\n",
    "        semierror = np.array(scores).mean()\n",
    "\n",
    "        ### naive evaluation\n",
    "        naivescores = []\n",
    "        for i in range(len(pids)):\n",
    "            pid = pids[i]\n",
    "            if i in representatives:\n",
    "                naivescores.append(lowerbound)\n",
    "                continue\n",
    "            gt = xdimgts[i]\n",
    "            repre = representatives[cluster_labels[i]]\n",
    "            xs = xdimgts[repre]\n",
    "            ma = np.array(gt).copy(order='C')\n",
    "            mb = np.array(xs).copy(order='C')\n",
    "            err1 = faiss_knn(ma,mb,n_neighbors=1)\n",
    "            err2 = faiss_knn(mb,ma,n_neighbors=1)\n",
    "            err = list(err1) + list(err2)\n",
    "            err = (np.array(err)).mean()\n",
    "            naivescores.append(err)\n",
    "        naiveerror = np.array(naivescores).mean()\n",
    "\n",
    "\n",
    "        normednaive = (naiveerror - lowerbound)/(upperbound - lowerbound)\n",
    "        normedsemi = (semierror - lowerbound)/(upperbound - lowerbound)\n",
    "        t_end = timeit.default_timer()\n",
    "        print('naive:',naiveerror)\n",
    "        print('semi:',semierror)\n",
    "        print('upperbound:',upperbound)\n",
    "        print('lowerbound;',lowerbound)\n",
    "        print('normed naive:',normednaive)\n",
    "        print('normed semi:',normedsemi)\n",
    "        print(str(t_end-t_start),' for evaluation')\n",
    "        \n",
    "        f=open('performance/passive'+str(rnd)+'.txt','w')\n",
    "        f.write('naive:'+str(naiveerror)+'\\n')\n",
    "        f.write('semi:'+str(semierror)+'\\n')\n",
    "        f.write('upperbound:'+str(upperbound)+'\\n')\n",
    "        f.write('lowerbound;'+str(lowerbound)+'\\n')\n",
    "        f.write('normed naive:'+str(normednaive)+'\\n')\n",
    "        f.write('normed semi:'+str(normedsemi)+'\\n')\n",
    "        f.close()\n",
    "        ### end of evaluation\n",
    "\n",
    "\n",
    "        ### active learning \n",
    "        \n",
    "        \n",
    "        nrep, nlabels = passive_pick_batch(reduced_bulk=reduced_bulk,\\\n",
    "                        representatives=representatives,\\\n",
    "                        cluster_labels=cluster_labels,\\\n",
    "                        xdimsemis=xdimsemis,\\\n",
    "                        xdimgts=xdimgts,\\\n",
    "                        discount_rate = 1,\\\n",
    "                        semi_dis_rate = 1,\\\n",
    "                        batch_size=BATCH_SIZE\\\n",
    "                       )\n",
    "        new_representatives = nrep\n",
    "        new_cluster_labels = nlabels\n",
    "        f=open('training_rec/eer_cluster_labels_'+str(rnd+1)+'.txt','w')\n",
    "        for i in range(len(new_cluster_labels)):\n",
    "            f.write(str(new_cluster_labels[i])+'\\n')\n",
    "        f.close()\n",
    "        f=open('training_rec/eer_representatives_'+str(rnd+1)+'.txt','w')\n",
    "        for i in range(len(new_representatives)):\n",
    "            f.write(str(new_representatives[i])+'\\n')\n",
    "        f.close()\n",
    "\n",
    "        cluster_labels = new_cluster_labels\n",
    "        representatives = new_representatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8be64-cc48-4718-93e5-f700a1718471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c641ec6-cd84-406b-88c4-1958576932eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 121.82691,\n",
       " 100.34202]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f182c81e-598e-4c6f-8b33-731cbef57c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.854675,\n",
       " 121.92378]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivescores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23938465-04b0-460a-80c0-995cd109786c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40b316-c169-4a72-b1af-a56831951b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fdda9-7da8-45ee-995b-a94f776f8049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe99bcf-8137-490a-8c2a-de64cc36fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d4875-9acd-4e3d-827e-b829deaaa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31243d9-6e1d-4c7f-bc76-7f5d423d8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "naivescores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d2540-1c9b-40f7-87c8-70d95c670677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0577c9-6489-4931-ae5b-b6edb22fa7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23c30c-8bc6-4742-aaca-08d63f70fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52de432-903a-4502-8c5d-d04752a3d6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
